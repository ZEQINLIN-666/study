# 4.6

# HTTP

## 简述什么是HTTP?

HTTP协议全程叫超文本传输协议。是基于TCP的应用层协议。
http协议定义Web客户端如何从Web服务器请求Web页面，以及服务器如何把Web页面传送给客户端。

HTTP协议采用了请求/响应模型。客户端向服务器发送一个请求报文，请求报文包含请求的方法、URL、协议版本、请求头部和请求数据。服务器以一个状态行作为响应，响应的内容包括协议的版本、成功或者错误代码、服务器信息、响应头部和响应数据。

HTTP是不保存状态的协议，既无状态协议，协议本身对于请求或响应之间的通信状态不进行保存，因此连接双方不能知晓对方当前的身份和状态。

这也是Cookie技术产生的重要原因之一：客户端的状态管理。浏览器会根据从服务器端发送的响应报文内 Set-Cookie 首部字段信息自动保持 Cookie。而每次客户端发送 HTTP 请求，都会在请求报文中携带 Cookie，作为服务端识别客户端身份状态的标识。

## Http的优缺点

**特点**：`无连接`、`无状态`、`灵活`、`简单快速`

- **无连接（短链接）**：每一次请求都要连接一次，请求结束就会断掉，不会保持连接
- **无状态**：每一次请求都是独立的，请求结束不会记录连接的任何信息(**提起裤子就不认人的意思**)，减少了网络开销，这`是优点也是缺点`
- **灵活**：通过http协议中头部的`Content-Type`标记，可以传输任意数据类型的数据对象(文本、图片、视频等等)，非常灵活
- **简单快速**：发送请求访问某个资源时，只需传送请求方法和URL就可以了，使用简单，正由于http协议简单，使得http服务器的程序规模小，因而通信速度很快

**缺点**：`无状态`、`不安全`、`明文传输`、`队头阻塞`

- **无状态**：请求不会记录任何连接信息，没有记忆，就无法区分多个请求发起者身份是不是同一个客户端的，意味着如果后续处理需要前面的信息，则它必须重传，这样可能导致每次连接传送的数据量增大。（加购，下单，支付都需要验证身份）
- **不安全**：`明文传输`可能被窃听不安全，缺少`身份认证`也可能遭遇伪装，还有缺少`报文完整性验证`可能遭到篡改
- **明文传输**：报文(header部分)使用的是明文，直接将信息暴露给了外界，`WIFI陷阱`就是复用明文传输的特点，诱导你连上热点，然后疯狂抓取你的流量，从而拿到你的敏感信息
- **队头阻塞**：开启`长连接`(下面有讲)时，只建立一个TCP连接，同一时刻只能处理一个请求，那么当请求耗时过长时，其他请求就只能阻塞状态

## HTTP请求方法

## HTTP 请求方法(9种)

**HTTP1.0：** `GET`、`POST`、`HEAD`

**HTTP1.1：** `PUT`、`PATCH`、`DELETE`、`OPTIONS`、`TRACE`、`CONNECT`

| 方法     | 描述                                                         |
| -------- | ------------------------------------------------------------ |
| **GET**  | 获取资源，GET 方法用来请求访问已被 URI 识别的资源。指定的资源经服务器端解析后返回响应内容。也就是说，如果请求的资源是文本，那就保持原样返回； |
| **POST** | `POST 传输实体`，虽然 GET 方法也可以传输主体信息，但是便于区分，我们一般不用 GET 传输实体信息，反而使用 POST 传输实体信息，通常会造成服务器资源的修改 |
| **HEAD** | HEAD 获得响应首部，HEAD 方法和 GET 方法一样，只是不返回报文主体部分。用于确认 URI 的有效性及资源更新的日期时间等。 |
| PUT      | PUT 传输文件，PUT 方法用来传输文件。就像 FTP 协议的文件上传一样，要求在请求报文的主体中包含文件内容，然后保存到请求 URI 指定的位置。<br/>但是，鉴于 HTTP 的 PUT 方法自身不带验证机制，任何人都可以上传文件 , 存在安全性问题，因此一般的 W eb 网站不使用该方法。若配合 W eb 应用程序的验证机制，或架构设计采用REST（REpresentational State Transfer，表征状态转移）标准的同类 Web 网站，就可能会开放使用 PUT 方法。 |
| PATCH    | 对PUT的补充，对已知资源部分更新                              |
| DELETE   | 删除资源。DELETE 删除文件，DELETE 方法用来删除文件，是与 PUT 相反的方法。DELETE 方法按请求 URI 删除指定的资源 |
| OPTIONS  | 列出请求资源支持的请求方法，用来跨域请求                     |
| TRACE    | 追踪请求/响应路径，用于测试或诊断。TRACE 方法是让 Web 服务器端将之前的请求通信环回给客户端的方法。 |
| CONNECT  | CONNECT 要求用隧道协议连接代理，CONNECT 方法要求在与代理服务器通信时建立隧道，实现用隧道协议进行 TCP 通信。主要使用 `SSL（Secure Sockets Layer，安全套接层）`和 TLS`（Transport Layer Security，传输层安全）`协议把通信内容加 密后经网络隧道传输。 |

### GET 和 POST 的区别

- `GET`在浏览器回退时是无害的，而`POST`会再次发起请求
- `GET`请求会被浏览器主动缓存，而`POST`不会，除非手动设置
- `GET`请求参数会被保留在浏览器历史记录里，而`POST`中的参数不会被保留
- `GET`请求在`URL`中传递的参数有长度限制(浏览器限制大小不同)，而`POST`没有限制
- `GET`参数通过`URL`传递，`POST`放在`Request body`中
- `GET`产生的URL地址可以被收藏，而`POST`不可以
- `GET`没有`POST`安全，因为`GET`请求参数直接暴露在`URL`上，所以不能用来传递敏感信息
- `GET`请求只能进行`URL`编码，而`POST`支持多种编码方式
- 对参数的数据类型，`GET`只接受`ASCII`字符，而`POST`没有限制
- `GET`产生一个TCP数据包，`POST`产生两个数据包(Firefox只发一次)。GET浏览器把 http header和data一起发出去，响应成功200，POST先发送header，响应100 continue，再发送data，响应成功200

- GET ⽅法是安全且幂等的，因为它是「只读」操作，⽆论操作多少次，服务器上的数据都是安全 的，且每次的结果都是相同的。 POST 因为是「新增或提交数据」的操作，会修改服务器上的资源，所以是不安全的，且多次提交数据就会创建多 个资源，所以不是幂等的。

### HTTP的get方法如何判断数据传输完毕

- HTTP协议的服务端响应报文里有Content-Length字段，明确了报文的长度。客户端应该是通过这个来判断的。

### POST 有哪几种编码方式

- urlencoded

  ```http
  POST http://www.example.com HTTP/1.1
  Content-Type: application/x-www-form-urlencoded;charset=utf-8
  
  title=test&sub%5B%5D=1&sub%5B%5D=2&sub%5B%5D=3
  ```

  Content-Type 被指定为 application/x-www-form-urlencoded；其次，提交的数据按key1=val1&key2=val2 的方式进行编码，key 和 val 都进行了 URL 转码。

- multipart/form-data

  这又是一个常见的 POST 数据提交的方式。我们使用表单上传文件时，必须让 <form> 表单的 `enctype` 等于 multipart/form-data

- application/json

  用来告诉服务端消息主体是序列化后的 JSON 字符串

  ```http
  POST http://www.example.com HTTP/1.1 
  Content-Type: application/json;charset=utf-8
  
  {"title":"test","sub":[1,2,3]}
  ```

- text/xml

### 为什么post要分两次发送(大文件可以先验证文件信息)

Post请求发送一次还是两次，取决与浏览器自己的实现。

**比如上传文件的场景，请求头中有文件的名字等信息，请求体是文件本身，如果文件很大就可以分别发送，先验证请求头，文件名等信息是否符合要求，如果不符合就没有必要发送请求体了。**

另外Ajax是会分两次发送的，这是因为Ajax使用了XMLHttpRequest API，浏览器会先发送请求头吗，再发送请求体，但是火狐浏览器不会。
所以Post请求到底是发送一次还是两次，取决于浏览器的实现，不论一次还是两次都是符合标准的。



## HTTP 报文组成部分

**http报文**：由`请求报文`和`响应报文`组成

**请求报文**：由`请求行`、`请求头`、`空行`、`请求体`四部分组成

**响应报文**：由`状态行`、`响应头`、`空行`、`响应体`四部分组成

- **请求行**：包含http方法，请求地址，http协议以及版本
- **请求头/响应头**：就是一些key:value来告诉服务端我要哪些内容，要注意什么类型等，[请求头/响应头每一个字段详解](https://link.juejin.cn?target=https%3A%2F%2Fkb.cnblogs.com%2Fpage%2F92320%2F)
- **空行**：用来区分首部与实体，因为请求头都是key:value的格式，当解析遇到空行时，服务端就知道下一个不再是请求头部分，就该当作请求体来解析了
- **请求体**：请求的参数
- **状态行**：包含http协议及版本、数字状态码、状态码英文名称
- **响应体**：服务端返回的数据

```dart
GET         /s?wd=nihao  HTTP/2.0  —— 请求行（Request Line）
方法(method) 路径(Path)   HTTP版本(version)

Host: www.baidu.com      |
Content-Type: text/html  |   Headers（键值对）
Content-Length: 243      |

bodybodybodybodybody  —— Body(注意Get请求方式是没有Body的，这里只是举例说明。所以Get的参数只要放入路径Path中就好)
```

![img](https://upload-images.jianshu.io/upload_images/8654767-0254ee6430baf17f.png?imageMogr2/auto-orient/strip|imageView2/2/w/600/format/webp)

### Http header(头)的内容

#### Requests部分

|     Header      |                             解释                             |                       示例                        |
| :-------------: | :----------------------------------------------------------: | :-----------------------------------------------: |
|     Accept      |                 指定客户端能够接收的内容类型                 |           Accept: text/plain, text/html           |
| Accept-Charset  |                 浏览器可以接受的字符编码集。                 |            Accept-Charset: iso-8859-5             |
| Accept-Encoding |     指定浏览器可以支持的web服务器返回内容压缩编码类型。      |          Accept-Encoding: compress, gzip          |
| Accept-Language |                      浏览器可接受的语言                      |              Accept-Language: en,zh               |
|  Authorization  |                      HTTP授权的授权证书                      | Authorization: Basic QWxhZGRpbjpvcGVuIHNlc2FtZQ== |
|  Cache-Control  |                 指定请求和响应遵循的缓存机制                 |              Cache-Control: no-cache              |
|   Connection    |      表示是否需要持久连接。（HTTP 1.1默认进行持久连接）      |                 Connection: close                 |
|     Cookie      | HTTP请求发送时，会把保存在该请求域名下的所有cookie值一起发送给web服务器。 |           Cookie: $Version=1; Skin=new;           |
| Content-Length  |                        请求的内容长度                        |                Content-Length: 348                |
|  Content-Type   |              告诉服务端本次请求的数据是什么格式              |  Content-Type: application/x-www-form-urlencoded  |
|      Date       |                     请求发送的日期和时间                     |        Date: Tue, 15 Nov 2010 08:12:31 GMT        |
|      Host       |                指定请求的服务器的域名和端口号                |                Host: www.zcmhi.com                |
|   User-Agent    |                    包含发出请求的用户信息                    |       User-Agent: Mozilla/5.0 (Linux; X11)        |

#### Responses 部分

|      Header      |                   解释                   |                  示例                  |
| :--------------: | :--------------------------------------: | :------------------------------------: |
|  Cache-Control   | 告诉所有的缓存机制是否可以缓存及哪种类型 |        Cache-Control: no-cache         |
| Content-Encoding |  web服务器支持的返回内容压缩编码类型。   |         Content-Encoding: gzip         |
| Content-Language |               响应体的语言               |        Content-Language: en,zh         |
|  Content-Length  |               响应体的长度               |          Content-Length: 348           |
|   Content-Type   |            返回内容的MIME类型            | Content-Type: text/html; charset=utf-8 |

### Http中的content-type有哪些

MediaType，即是Internet Media Type，互联网媒体类型；也叫做MIME类型，在Http协议消息头中，使用Content-Type来表示具体请求中的媒体类型信息。

 例如： Content-Type: text/html;charset:utf-8;

 一、常见的媒体格式类型如下：

-   text/html ： HTML格式
-   text/plain ：纯文本格式   
-   text/xml ： XML格式
-   image/gif ：gif图片格式  
-   image/jpeg ：jpg图片格式 
-   image/png：png图片格式

  二、以application开头的媒体格式类型：

-   application/xhtml+xml ：XHTML格式
-   application/xml   ： XML数据格式
-   application/atom+xml ：Atom XML聚合格式  
-   application/json  ： JSON数据格式
-   application/pdf    ：pdf格式 
-   application/msword ： Word文档格式
-   application/octet-stream ： 二进制流数据（如常见的文件下载）
-   application/x-www-form-urlencoded ： <form encType=””>中默认的encType，form表单数据被编码为key/value格式发送到服务器（表单默认的提交数据的格式）

  三、另外一种常见的媒体格式是上传文件之时使用的：

-   multipart/form-data ： 需要在表单中进行文件上传时，就需要使用该格式

   以上就是我们在日常的开发中，经常会用到的若干content-type的内容格式。



### 状态码

> ### 100 Continue
>
> 表示目前为止一切正常, 客户端应该继续请求, 如果已完成请求则忽略.
>
> 为了让服务器检查请求的首部, 客户端必须在发送请求实体前, 在初始化请求中发送 Expect: 100-continue 首部并接收 100 Continue 响应状态码.
>
> #### Expect
>
> 包含一个期望条件，表示服务器只有在满足此期望条件的情况下才能妥善地处理请求。
>
> 规范中只规定了一个期望条件，即 Expect: 100-continue, 对此服务器可以做出如下回应：
>
> - 100 如果消息头中的期望条件可以得到满足，使得请求可以顺利进行的话，
> - 417 (Expectation Failed) 如果服务器不能满足期望条件的话；也可以是其他任意表示客户端错误的状态码（4xx）。
>
> 
>
> ### 200 OK
>
> 表明请求已经成功. 默认情况下状态码为200的响应可以被缓存。
>
> ### 204 No Content
>
> 表示目前请求成功，但客户端不需要更新其现有页面。
>
> 使用惯例是，在 PUT 请求中进行资源更新，但是不需要改变当前展示给用户的页面，那么返回 204 No Content。如果新创建了资源，那么返回 201 Created 。如果页面需要更新以反映更新后的资源，那么需要返回 200 。
>
> 
>
> ### 301 Moved Permanently
>
> 永久重定向。说明请求的资源已经被移动到了由 Location 头部指定的 url 上，是固定的不会再改变。搜索引擎会根据该响应修正。
>
> ### 308 Permanent Redirect
>
> 永久重定向。类似 301，区别在于能够确保请求方法和消息主体不会发生改变。
>
> > 尽管标准要求浏览器在收到该响应并进行重定向时不应该修改 http method 和 body，但是有一些浏览器可能会有问题。
> >
> > 所以最好是在应对 GET 或 HEAD 方法时使用 301，其他情况使用 308 来替代 301
>
> 
>
> ### 302 Found
>
> 临时重定向。重定向状态码表明请求的资源被暂时的移动到了由 Location 头部指定的 URL 上。浏览器会重定向到这个URL，但是搜索引擎不会对该资源的链接进行更新。
>
> ### 307 Temporary Redirect
>
> 临时重定向。类似 302，区别在于能够确保请求方法和消息主体不会发生改变。
>
> - 即使规范要求浏览器在重定向时保证请求方法和请求主体不变，但并不是所有的用户代理都会遵循这一点，你依然可以看到有缺陷的软件的存在。所以推荐仅在响应 GET 或 HEAD 方法时采用 302 状态码，而在其他时候使用 307  来替代，因为在这些场景下方法变换是明确禁止的。
> - 在确实需要将重定向请求的方法转换为 GET 的场景下，可以使用 303。例如在使用 PUT 方法进行文件上传操作时，需要返回确认信息（例如“你已经成功上传了xyz”）而不是上传的资源本身，就可以使用这个状态码。
>
> ### 303 See Other
>
> 通常作为 PUT 或 POST 操作的返回结果，它表示重定向链接指向的不是新上传的资源，而是另外一个页面，比如消息确认页面或上传进度页面。而请求重定向页面的方法要总是使用 GET。
>
> ### 304 Not Modified
>
> 说明无需再次传输请求的内容，也就是说可以使用缓存的内容。这通常是在一些安全的方法（safe），例如GET 或HEAD, 或在请求中附带了头部信息： If-None-Match 或If-Modified-Since。
>
> 如果返回 200，响应会带有头部 Cache-Control, Content-Location, Date, ETag, Expires，和 Vary.
>
> #### Last-Modified 和 If-Modified-Since
>
> 1. 客户端请求一个文件（A）。 服务器返回文件A，并返回 Last-Modified。
> 2. 客户端收到响应后，缓存文件A 和 Last-Modified。
> 3. 客户端再次请求文件A 时，发现该文件有 Last-Modified ，那么 header 离包含 If-Modified-Since，这个时间就是缓存文件的 Last-Modified。
> 4. 服务端收到请求，只需要判断这个时间和当前请求的文件的修改时间就可以确定是返回 304 还是 200
>
> If-Modified-Since 的主要缺点是只能精确到秒的级别，一旦在一秒内出现多次修改，是无法判断出已修改的状态。所以一般用在对时间不太敏感的静态资源。
>
> #### ETag 和 If-None-Match
>
> 1. 客户端请求一个文件（A）。 服务器返回文件A，并在给A加上一个 ETag。
> 2. 客户端收到响应后，并将文件连同 ETag 一起缓存。
> 3. 客户再次请求文件A，会发送 If-None-Match，内容是缓存该文件A的 Etag 值
> 4. 服务器检查该 ETag，和计算出来的 Etag 匹配，来判断文件是否未被修改。如果未修改就直接返回 304 和一个空的响应体。否则返回 200 和 文件。
>
> 当与  If-Modified-Since  一同使用的时候，If-None-Match 优先级更高（假如服务器支持的话）
>
> 
>
> ### 400 Bad Request
>
> 表示由于语法无效，服务器无法理解该请求。客户端不应该在未经修改的情况下重复此请求。
>
> ### 401 Unauthorized
>
> 说明由于缺乏目标资源要求的身份验证凭证，发送的请求未得到满足。
>
> 这个状态码会与 WWW-Authenticate 首部一起发送，其中包含有如何进行验证的信息。
>
> ### 403 Forbidden
>
> 指的是服务器端有能力处理该请求，但是拒绝授权访问。进入该状态后，不能再继续进行验证。该访问是永久禁止的，并且与应用逻辑密切相关（例如不正确的密码）
>
> ### 404 Not Found
>
> 说明服务器端无法找到所请求的资源。返回该响应的链接通常称为坏链（broken link）或死链（dead link），它们会导向链接出错处理
>
> 404 不能说明请求的资源是临时还是永久丢失。如果服务器知道该资源是永久丢失，那么应该返回 410 (Gone) 而不是 404 。
>
> ### 410 Gone
>
> 说明请求的内容在服务器上不存在了，同时是永久性的丢失。如果不清楚是否为永久或临时的丢失，应该使用404。
>
> ### 405 Method Not Allowed
>
> 表明服务器禁止了使用当前 HTTP 方法的请求。需要注意的是，GET 与 HEAD 两个方法不得被禁止，当然也不得返回状态码 405。
>
> ### 406 Not Acceptable
>
> 表示服务器端不支持 Accept、Accept-Charset、Accept-Encoding、 Accept-Language header 所要求的。
>
> > #### Accept 和 Content-Type
> >
> > Accept 用来告知服务端。客户端可以处理的内容类型，这种内容类型用 [MIME](https://link.juejin.cn?target=https%3A%2F%2Fdeveloper.mozilla.org%2Fzh-CN%2Fdocs%2FWeb%2FHTTP%2FBasics_of_HTTP%2FMIME_types) 类型来表示。服务器从中选择一项进行应用，并使用 Content-Type 应答头通知客户端。
> >
> > ```
> > Accept: <MIME_type>/<MIME_subtype>
> > Accept: <MIME_type>/*
> > Accept: */*
> > 
> > // Multiple types, weighted with the quality value syntax:
> > Accept: text/html, application/xhtml+xml, application/xml;q=0.9, */*;q=0.8
> > 复制代码
> > ```
> >
> > - <MIME_type>/<MIME_subtype> : A single, precise MIME type, like text/html.
> > - <MIME_type>/* :  A MIME type, but without any subtype. image/* will match image/png, image/svg, image/gif and any other image types.
> > - */* : Any MIME type
> > - ;q= (q-factor weighting)
> >
> > #### Accept-Encoding 和 Content-Encoding
> >
> > Accept-Encoding 会将客户端能够理解的内容编码方式——通常是某种压缩算法——进行通知。服务端会从中选择一个使用，并在响应报文首部 Content-Encoding 中通知客户端。
> >
> > ```
> > Accept-Encoding: deflate, gzip;q=1.0, *;q=0.5
> > 
> > Content-Encoding: gzip
> > ```
>
> 
>
> ### 409 Conflict（版本冲突）
>
> 表示请求与服务器端目标资源的当前状态相冲突。
>
> 冲突最有可能发生在对 PUT 请求的响应中。例如，当上传文件的版本比服务器上已存在的要旧，从而导致版本冲突的时候，那么就有可能收到状态码为 409 的响应。
>
> 
>
> ### 500 Internal Server Error
>
> 表示所请求的服务器遇到意外的情况并阻止其执行请求。
>
> 举例：代码语法错误；php代码运行内存超了内存限制 memory_limit；nginx config 配置错误；
>
> ### 502 Bad Gateway
>
> 表示作为网关或代理角色的服务器Nginx，从上游服务器（如tomcat、php-fpm）中接收到的响应是无效的。
>
> 举例： tomcat 挂掉了，后端服务器tomcat没有起来，应用服务的问题
>
> ### 503 Service Unavailable
>
> 表示服务器尚未处于可以接受请求的状态。通常造成这种情况的原因是由于服务器停机维护或者已超载。该种响应应该用于临时状况下，与之同时，在可行的情况下，应该在 Retry-After 首部字段中包含服务恢复的预期时间。
>
> 举例：服务器停机维护时，主动用503响应请求；nginx 设置限速之类的，超过限速，会返回503。
>
> 
>
> >#### Retry-After
> >
> >表示用户代理需要等待多长时间之后才能继续发送请求。
> >
> >```http
> >Retry-After: Wed, 21 Oct 2015 07:28:00 GMT
> >Retry-After: 120
> >```
>
> 
>
> ### 504 Gateway Timeout
>
> 表示网关或者代理的服务器无法在规定的时间内获得想要的响应。
>
> 举例：代码执行时间超时，或死循环了。

#### 301和302的区别

> ### 在应用方面：
>
> #### 301适合永久重定向
>
> 301比较常用的场景是使用域名跳转。
>
> 比如，我们访问 **http**://www.baidu.com 会跳转到 **https**://www.baidu.com，发送请求之后，就会返回301状态码，然后返回一个location，提示新的地址，浏览器就会拿着这个新的地址去访问。 
>
> **注意： 301请求是可以缓存的， 即通过看status code，可以发现后面写着from cache。**
>
>  **或者你把你的网页的名称从php修改为了html，这个过程中，也会发生永久重定向。**
>
> #### **302用来做临时跳转**
>
> 比如未登陆的用户访问用户中心重定向到登录页面。
>
> 访问404页面会重新定向到首页。 
>
> ## 在搜索引擎的角度
>
> 　　302重定向只是暂时的重定向，搜索引擎会抓取新的内容而保留旧的地址，**因为服务器返回302，所以，搜索搜索引擎认为新的网址是暂时的。**
>
> 　　**而301重定向是永久的重定向，搜索引擎在抓取新的内容的同时也将旧的网址替换为了重定向之后的网址。**



## HTTP的演化

#### **一、HTTP1.0:**

- 短连接，每次请求都要创建连接
- 请求-响应模型，上一个请求得到响应之后才能继续发送请求。

#### **二、HTTP1.1:**

> ### HTTP/1.1 相⽐ HTTP/1.0 提⾼了什么性能？
>
> HTTP/1.1 相⽐ HTTP/1.0 性能上的改进：（长连接+管道） 
>
> 一、使⽤ TCP ⻓连接的⽅式改善了 HTTP/1.0 短连接（每一个请求，都会建立连接）造成的性能开销。在HTTP1.1中默认开启Connection： keep-alive 
>
> 二、⽀持管道（pipeline）⽹络传输，只要第⼀个请求发出去了，不必等其回来，就可以发第⼆个请求出去，可以减少整体的响应时间
>
> ### HTTP/1.1 的性能瓶颈：
>
> 1. 请求 / 响应头部（Header）未经压缩就发送，⾸部信息越多延迟越⼤。只能压缩 消息体Body 的部分； 
> 2. 发送冗⻓的⾸部。每次互相发送相同的⾸部造成的浪费较多； 
> 3. 服务器是按请求的顺序响应的，如果服务器响应慢，会招致客户端⼀直请求不到数据，也就是队头阻塞； 
> 4. 没有请求优先级控制； 
> 5. 请求只能从客户端开始，服务器只能被动响应
>
> ### http1.1 为什么无法做到多路复用
>
> **HTTP/2是基于二进制“帧”的协议，HTTP/1.1是基于“文本分割”解析的协议。**
>
> HTTP/1.1发送请求消息的文本格式：以换行符分割每一条key:value的内容，“服务端”需要不断的读入字节，直到遇到分隔符（这里指换行符，代码中可能使用/n或者/r/n表示），这种解析方式是可行的，并且HTTP/1.1已经被广泛使用了二十多年，这事已经做过无数次了，问题一直都是存在的：
>
> - 一次只能处理一个请求或响应，因为这种以分隔符分割消息的数据，在完成之前不能停止解析。
> - 解析这种数据无法预知需要多少内存，这会带给“服务端”很大的压力，因为它不知道要把一行要解析的内容读到多大的“缓冲区”中，在保证解析效率和速度的前提下：内存该如何分配？

#### 三、HTTP2

> ### 针对HTTP/1.1 的性能瓶颈， HTTP/2 做了什么优化？
>
> HTTP/2 协议是基于 HTTPS 的，所以 HTTP/2 的安全性也是有保障的。 
>
> 1. **头部压缩** HTTP/2 会压缩头（Header）如果你同时发出多个请求，他们的头是⼀样的或是相似的，那么，协议会帮你消除重复的部分。 
>
>    这就是所谓的 HPACK 算法：在客户端和服务器同时维护⼀张头信息表，所有字段都会存⼊这个表，⽣成⼀个索引号，以后就不发送同样字段了，只发送索引号，这样就提⾼速度了。 
>
> 2. **⼆进制格式** HTTP/2 不再像 HTTP/1.1 ⾥的纯⽂本形式的报⽂，⽽是全⾯采⽤了⼆进制格式，头信息和数据体都是⼆进制，并且统称为帧（frame）： 头信息帧和数据帧。服务端在收到报⽂后，⽆需再将明⽂的报⽂转成⼆进制，⽽是直接解析⼆进制报⽂，这增加了数据传输的效率 
>
>    ![图片描述](https://image-static.segmentfault.com/264/608/2646086523-5be7a579c6b6e_articlex)
>
>    帧的字节中保存了不同的信息，前9个字节对于每个帧都是一致的，“服务器”解析HTTP/2的数据帧时只需要解析这些字节，就能准确的知道整个帧期望多少字节数来进行处理信息
>
> 3. **数据流** HTTP/2 的数据包不是按顺序发送的，同⼀个连接⾥⾯连续的数据包，可能属于不同的回应。因此，必须要对数据包做标记，指出它属于哪个回应。 
>
>    ![图片描述](https://image-static.segmentfault.com/649/701/649701929-5be7b76c29006_articlex)
>
>    每个请求或回应的所有数据包，称为⼀个数据流（ Stream ）。每个数据流都标记着⼀个独⼀⽆⼆的编号，其中规定客户端发出的数据流编号为奇数， 服务器发出的数据流编号为偶数
>
>    客户端还可以指定数据流的优先级。优先级⾼的请求，服务器就先响应该请求。 
>
> 4. **多路复⽤** HTTP/2 是可以在⼀个连接中并发多个请求或回应，⽽不⽤按照顺序⼀⼀对应。 移除了 HTTP/1.1 中的串⾏请求，不需要排队等待，也就不会再出现「队头阻塞」问题， 降低了延迟，⼤幅度提⾼了连接的利⽤率 
>
>    举例来说，在⼀个 TCP 连接⾥，服务器收到了客户端 A 和 B 的两个请求，如果发现 A 处理过程⾮常耗时，于是就回应 A 请求已经处理好的部分，接着回应 B 请求，完成后，再回应 A 请求剩下的部分 
>
> 5. **服务器推送** HTTP/2 还在⼀定程度上改善了传统的「请求 - 应答」⼯作模式，服务不再是被动地响应，也可以主动向客户端发送消息。 举例来说，在浏览器刚请求 HTML 的时候，就提前把可能会⽤到的 JS、 CSS ⽂件等静态资源主动发给客户端， 减少延时的等待，也就是服务器推送（Server Push，也叫 Cache Push）

#### 四、HTTP3

> ### http3.0解决了http2.0的什么问题
>
> HTTP/2 主要的问题在于，多个 HTTP 请求在复⽤⼀个 TCP 连接，下层的 TCP 协议是不知道有多少个 HTTP 请求的。所以⼀旦发⽣了丢包现象，就会触发 TCP 的重传机制，这样在⼀个 TCP 连接中的所有的 HTTP 请求都必须等待这个丢了的包被重传回来。 
>
> HTTP/1.1 中的管道（ pipeline）传输中如果有⼀个请求阻塞了，那么队列后请求也统统被阻塞住了。 HTTP/2 多个请求复⽤⼀个TCP连接，⼀旦发⽣丢包，就会阻塞住所有的 HTTP 请求。 
>
>  这都是基于 TCP 传输层的问题，所以 HTTP/3 把 HTTP 下层的 TCP 协议改成了 UDP！ UDP 发⽣是不管顺序，也不管丢包的，所以不会出现 HTTP/1.1 的队头阻塞 和 HTTP/2 的⼀个丢包全部重传问 题



## 长连接与短连接的区别

HTTP分为长连接和短连接，其实本质上是说的TCP连接。TCP连接是一个双向的通道，它是可以保持一段时间不关闭的，因此TCP连接才有真正的长连接和短连接这一说。

长连接是为了复用，多个HTTP请求可以复用同一个TCP连接，这就节省了很多TCP连接建立和断开的消耗。

比如你请求了一个网页，这个网页里肯定还包含了CSS、JS等等一系列资源，如果你是短连接（也就是每次都要重新建立TCP连接）的话，那你每打开一个网页，基本要建立几个甚至几十个TCP连接，这浪费了多少资源。

但如果是长连接的话，那么这么多次HTTP请求（这些请求包括请求网页内容，CSS文件，JS文件，图片等等），其实使用的都是一个TCP连接，很显然是可以节省很多消耗的。

注意：长连接并不是永久连接的。如果一段时间内（具体的时间长短，是可以在header当中进行设置的，也就是所谓的超时时间），这个连接没有HTTP请求发出的话，那么这个长连接就会被断掉。



> http缓存（强缓存和协商缓存
>
> - 不向服务器发送请求
> - 向服务器发送请求，服务器根据请求参数检查资源是否过期。
>
> Http缓存定义与原理
> 立足于http协议解释，为何第二次从网页上下载图片会变快
>
> - 缓存没过期，直接从本地缓存拿
> - 服务器资源没变，返回304，不用再去磁盘取资源
>
> 下载文件时下载速度为什么会先上升再平滑？
>
> - 慢启动
>
> Cache-Concrol和expire的区别
>
> - 相对时间和绝对时间
>
> no-cache 和 no-store 的区别
>
> - 不检查缓存，直接请求服务器，如果资源没变，返回304
> - 不设置缓存，直接请求服务器，服务器也要从磁盘下载资源。

## HTTP缓存

#### 1. 什么是缓存？

浏览器缓存(Brower Caching)是浏览器对之前请求过的文件进行缓存，以便下一次访问时重复使用，节省带宽，提高访问速度，降低服务器压力

http缓存机制主要在http响应头中设定，响应头中相关字段为Expires、Cache-Control、Last-Modified、Etag。



优点：

- 大大减少带宽。
- 由于减少了服务器资源下载时间，相应的提高了用户体验。

缺点：服务器上 资源更新时，浏览器感知不到，拿不到最新的 资源。

#### 2.缓存的类别

**浏览器缓存分为强缓存和协商缓存**

强缓存：浏览器不会向服务器发送任何请求，直接从本地缓存中读取文件并返回Status Code: 200 OK



![img](https://p1-jj.byteimg.com/tos-cn-i-t2oaga2asx/gold-user-assets/2019/5/6/16a8bc0c7e54f6ec~tplv-t2oaga2asx-zoom-in-crop-mark:1304:0:0:0.awebp)





![img](https://p1-jj.byteimg.com/tos-cn-i-t2oaga2asx/gold-user-assets/2019/5/6/16a8bdbc4b9c8720~tplv-t2oaga2asx-zoom-in-crop-mark:1304:0:0:0.awebp)



> 200 form memory cache : 不访问服务器，一般已经加载过该资源且缓存在了内存当中，直接从内存中读取缓存。浏览器关闭后，数据将不存在（资源被释放掉了），再次打开相同的页面时，不会出现from memory cache。

> 200 from disk cache： 不访问服务器，已经在之前的某个时间加载过该资源，直接从硬盘中读取缓存，关闭浏览器后，数据依然存在，此资源不会随着该页面的关闭而释放掉下次打开仍然会是from disk cache。

> 优先访问memory cache,其次是disk cache，最后是请求网络资源

协商缓存: **向服务器发送请求**，服务器会根据这个请求的request header的一些参数来判断是否命中协商缓存，如果命中，则返回304状态码并带上新的response header通知浏览器从缓存中读取资源；



![img](https://p1-jj.byteimg.com/tos-cn-i-t2oaga2asx/gold-user-assets/2019/5/6/16a8bc3172e3a167~tplv-t2oaga2asx-zoom-in-crop-mark:1304:0:0:0.awebp)




#### 3.缓存相关参数

> #### 服务器和浏览器约定资源过期时间。（Expire）（绝对过期时间）
>
> **由服务器告诉客户端**
>
> 服务器和浏览器约定文件过期时间，用 Expires 字段来控制，时间是 GMT 格式的标准时间，如 Fri, 01 Jan 1990 00:00:00 GMT。
>
> - 浏览器第一次请求一个静态资源 a.js。（1KB）
> - 服务器把 a.js 和 a.js 的缓存过期时间(Expires：Mon, 26 Sep 2018 05:00:00 GMT)发给浏览器。（10+1=11KB）
>
> > 服务器告诉浏览器：你把我发给你的 a.js 文件缓存到你那里，在 2018年9月26日5点之前不要再发请求烦我，直接使用你自己缓存的 a.js 就行了。
>
> - 浏览器接收到 a.js，同时记住了过期时间。
> - 在2018年9月26日5点之前，浏览器再次请求 a.js，便不再请求服务器，直接使用上一次缓存的 a.js 文件。（0KB）
> - 在2018年9月26日5点01分，浏览器请求 a.js，发现 a.js 缓存时间过了，于是不再使用本地缓存，而是请求服务器，**服务器又重新读取磁盘文件 a.js**，返给浏览器，同时告诉浏览器一个新的过期时间。（1+10+1=12KB）。
> - 如此往复。。。
>
> 该种方式较之前的方式有了很大的改善：
>
> - 在过期时间以内，为用户省了很多流量。
> - 减少了服务器重复读取磁盘文件的压力。
> - 缓存过期后，能够得到最新的 a.js 文件。
>
> 缺点还是有：
>
> - 缓存过期以后，服务器不管 a.js有没有变化，都会再次读取 a.js文件，并返给浏览器。
>
> 
>
> #### 服务器告诉浏览器资源上次修改时间。
>
> 为了解决上个方案的问题，服务器和浏览器经过磋商，制定了一种方案，服务器每次返回 a.js 的时候，还要告诉浏览器 a.js 在服务器上的最近修改时间 Last-Modified （GMT标准格式）。
>
> - 浏览器访问 a.js 文件。（1KB）
> - 服务器返回 a.js 的时候，告诉浏览器 a.js 文件。（10+1=11KB） 在服务器的上次修改时间 Last-Modified（GMT标准格式）以及缓存过期时间 Expires（GMT标准格式）
> - 当 a.js 过期时，浏览器带上 If-Modified-Since（等于上一次请求的Last-Modified） 请求服务器。（1KB）
> - 服务器比较请求头里的 Last-Modified 时间和服务器上 a.js的上次修改时间：
>   - 如果一致，则告诉浏览器：你可以继续用本地缓存（304）。此时，服务器不再返回 a.js 文件。（1KB）
>   - 如果不一致，服务器读取磁盘上的 a.js 文件返给浏览器，同时告诉浏览器 a.js 的最近的修改时间 Last-Modified 以及过期时间 Expires。（1+10=11KB）
>   - 如此往复。
>
> 此种方案比上一个方案有了更进一步的优化：
>
> - 缓存过期后，服务器检测如果文件没变化，不再把a.js发给浏览器，省去了 10KB 的流量。
> - 缓存过期后，服务器检测文件有变化，则把最新的 a.js 发给浏览器，浏览器能够得到最新的 a.js。
>
> 缺点：
>
> - Expires 过期控制不稳定，因为浏览器端可以随意修改时间，导致缓存使用不精准。
> - Last-Modified 过期时间只能精确到秒。
>
> 精确到秒存在两个问题：
>
> - 1、如果 a.js 在一秒时间内经常变动，同时服务器给 a.js  设置无缓存，那浏览器每次访问 a.js，都会请求服务器，此时服务器比较发给浏览器的上次修改时间和 a.js 的最近修改时间，发现都是在同一时间（因为精确到秒），因此返回给浏览器继续使用本地缓存的消息（304），但事实上服务器上的 a.js 已经改动了好多次了。所以这种情况，浏览器拿不到最新的 a.js 文件。
> - 2、如果在服务器上 a.js 被修改了，但其实际内容根本没发生改变，会因为 Last-Modified 时间匹配不上而重新返回 a.js 给浏览器。
>
> #### 继续改进，增加相对时间的控制，引入 Cache-Contorl（相对过期时间）
>
> 为了兼容已经实现了上述方案的浏览器，同时加入新的缓存方案，服务器除了告诉浏览器 Expires ，同时告诉浏览器一个相对时间 Cache-Control：max-age=10秒。意思是在10秒以内，使用缓存到浏览器的 a.js 资源。
>
> 浏览器先检查 Cache-Control，如果有，则以 Cache-Control 为准，忽略 Expires。如果没有 Cache-Control，则以 Expires 为准。
>
> 
>
> #### 继续改进，增加文件内容对比，引入Etag（唯一ID）
>
> 为了解决文件修改时间只能精确到秒带来的问题，我们给服务器引入 Etag 响应头，a.js 内容变了，Etag 才变。内容不变，Etag 不变，可以理解为 Etag 是文件内容的唯一 ID。 同时引入对应的请求头 If-None-Match，每次浏览器请求服务器的时候，都带上If-None-Match字段，该字段的值就是上次请求 a.js 时，服务器返回给浏览器的 Etag。
>
> - 浏览器请求 a.js。
> - 服务器返回 a.js，同时告诉浏览器过期绝对时间（Expires）以及相对时间（Cache-Control：max-age=10），以及a.js上次修改时间Last-Modified，以及 a.js 的Etag。
> - 10秒内浏览器再次请求 a.js，不再请求服务器，直接使用本地缓存。
> - 11秒时，浏览器再次请求 a.js，请求服务器，带上上次修改时间 If-Modified-Since 和上次的 Etag 值 If-None-Match。
> - 服务器收到浏览器的If-Modified-Since和Etag，发现有If-None-Match，则比较 If-None-Match 和 a.js 的 Etag 值，忽略If-Modified-Since的比较。
> - a.js 文件内容没变化，则Etag和If-None-Match 一致，服务器告诉浏览器继续使用本地缓存（304）。
> - 如此往复。
>
> 
>
> >  不管用 Expires 还是 Cache-Control，他们都只能够控制缓存是否过期，但是在缓存过期之前，浏览器是无法得知服务器上的资源是否变化的。只有当缓存过期后，浏览器才会发请求询问服务器。
>
> #### Cache-Control参数设置
>
> Cache-Control 除了可以设置 max-age 相对过期时间以外，还可以设置成如下几种值：
>
> - public，资源允许被中间服务器缓存。
>
> > 浏览器请求服务器时，如果缓存时间没到，中间服务器直接返回给浏览器内容，而不必请求源服务器。
>
> - private，资源不允许被中间代理服务器缓存。
>
> > 浏览器请求服务器时，中间服务器都要把浏览器的请求透传给服务器。
>
> - no-cache，浏览器不做缓存检查。
>
> > 每次访问资源，浏览器都要向服务器询问，如果文件没变化，服务器只告诉浏览器继续使用缓存（304）。
>
> - no-store，浏览器和中间代理服务器都不能缓存资源。
>
> > 每次访问资源，浏览器都必须请求服务器，并且，服务器不去检查文件是否变化，而是直接返回完整的资源。
>
> - must-revalidate，可以缓存，但是使用之前必须先向源服务器确认。
> - proxy-revalidate，要求缓存服务器针对缓存资源向源服务器进行确认。
> - s-maxage：缓存服务器对资源缓存的最大时间。
>
> Cache-Control 对缓存的控制粒度更细，包括缓存代理服务器的缓存控制。





## Http与Tcp的关系与区别

**HTTP协议 与 TCP协议 的区别**

**TCP协议是传输层协议**，主要解决数据如何在网络中传输，而HTTP是应用层协议，主要解决如何包装数据。

**TCP/IP和HTTP协议的关系**

我们在传输数据时，可以只使用（传输层）TCP/IP协议，但是那样的话，如果没有应用层，便无法识别数据内容，如果想要使传输的数据有意义，则必须使用到应用层协议，应用层协议有很多，比如HTTP、FTP、TELNET 等，也可以自己定义应用层协议。

WEB使用HTTP协议作应用层协议，以封装HTTP 文本信息，然后使用TCP/IP做传输层协议将它发到网络上。所以说，**Http协议是建立在TCP协议基础之上的**

## keep-alive在http和tcp/ip中的区别

**这两个完全是两样不同东西**，实现的层面也不同：

- HTTP 的 Keep-Alive，是由**应用层（用户态）** 实现的，称为 HTTP 长连接；

  HTTP 的 Keep-Alive 可以使用同一个 TCP 连接来发送和接收多个 HTTP 请求/应答，避免了连接建立和释放的开销，这个方法称为 **HTTP 长连接**。**从 HTTP 1.1 开始， 就默认是开启了 Keep-Alive**

  > 如果使用了 HTTP 长连接，如果客户端完成一个 HTTP 请求后，就不再发起新的请求，此时这个 TCP 连接一直占用着不是挺浪费资源的吗？
  >
  > 对没错，所以为了避免资源浪费的情况，web 服务软件一般都会提供 `keepalive_timeout` 参数，用来指定 HTTP 长连接的超时时间。
  >
  > 比如设置了 HTTP 长连接的超时时间是 60 秒，web 服务软件就会**启动一个定时器**，如果客户端在完后一个 HTTP 请求后，在 60 秒内都没有再发起新的请求，**定时器的时间一到，就会触发回调函数来释放该连接。**

- TCP 的 Keepalive，是由 **TCP 层（内核态）** 实现的，称为 TCP 保活机制；

  TCP 的 Keepalive 也叫 TCP 保活机制，该功能是由「内核」实现的，当客户端和服务端长达一定时间没有进行数据交互时，内核为了确保该连接是否还有效，就会发送探测报文，来检测对方是否还在线，然后来决定是否要关闭该连接。



## Http与Rpc的关系

![img](https://segmentfault.com/img/remote/1460000037470064)



1. 都是应用调用另外一个应用的方法的解决方案
2. HTTP还可以作为RPC的底层通信协议。







## 跨域（同源策略与解决方案todo）

http请求中的跨域问题，**说一说对跨域的了解**

- 浏览器的同源策略，会屏蔽跨域数据

  怎么才算跨域呢？

  1. 请求协议`http,https`的不同
  2. 域`domain`的不同
  3. 端口`port`的不同

- **跨域并不是请求发不出去，请求能发出去，服务端能收到请求并正常返回结果，只是结果被浏览器拦截了**。因为归根结底，跨域是为了阻止用户读取到另一个域名下的内容，Ajax 可以获取响应，浏览器认为这不安全，所以拦截了响应。

为什么代理之后就不存在跨域问题了？

- 服务器与服务器之间没有同源策略、

代理服务器和服务器之间存在跨域问题吗？

- 不存在

把allow-origin设置为*会有什么问题？

- 所有域名都可以访问，可跨域访问，但是前端不能携带cookie到服务端

**同源策略以及解决方案**



## Http建立连接的过程

连接建立流程步骤如下：



![img](https:////upload-images.jianshu.io/upload_images/4360127-84fd2150cff9f01e.png?imageMogr2/auto-orient/strip|imageView2/2/w/1112/format/webp)

HTTP连接流程

 第1步：TCP通过三次握手建立双方连接；
 第2步：客户端通过发送请求报文及请求数据给服务端；
 第3步：服务端返回响应报文及响应数据给客户端；
 第4步：TCP通过四次挥手进行断开连接。



## 简述HTTP的工作机制

浏览器通过Http向服务器发送请求，服务器返回响应，浏览器通过其渲染引擎，也就是内核，将服务器返回的响应渲染到浏览器上。

## Http可以长连接，但为何还是无状态？

在www应用还很简单的时候，这个应用只是被用来浏览内容。如果只是浏览内容的话，无状态的协议已经够了，这样实现可以减轻实现的负担，因为有状态的协议实现起来代价相对来说是很高的,比如内存空间。

## Http的无状态具体指的是什么

不保存前面请求的信息。假设一个购物场景，登录->添加购物车->下单->结算->支付，这系列操作都要知道用户的身份才行。但服务器不知道这些请求是有关联的，每次都要问一遍身份信息。



## cookie + session + token

> **分布式session，如何实现？**
>
> **浏览器禁用了Cookie以后还能用Session吗**

### 什么是 Cookie

- **HTTP 是无状态的协议（对于事务处理没有记忆能力，每次客户端和服务端会话完成时，服务端不会保存任何会话信息**）：每个请求都是完全独立的，服务端无法确认当前访问者的身份信息，无法分辨上一次的请求发送者和这一次的发送者是不是同一个人。所以服务器与浏览器为了进行会话跟踪（知道是谁在访问我），就必须主动的去维护一个状态，这个状态用于告知服务端前后两个请求是否来自同一浏览器。而这个状态需要通过 cookie 或者 session 去实现。
- **cookie 存储在客户端：** cookie 是服务器发送到用户浏览器并保存在本地的一小块数据，它会在浏览器下次向同一服务器再发起请求时被携带并发送到服务器上。
- **cookie 是不可跨域的：** 每个 cookie 都会绑定单一的域名，无法在别的域名下获取使用，**一级域名和二级域名之间是允许共享使用的**（**靠的是 domain）**。

### **cookie 重要的属性**

| 属性           | 说明                                                         |
| -------------- | ------------------------------------------------------------ |
| **name=value** | 键值对，设置 Cookie 的名称及相对应的值，都必须是**字符串类型** - 如果值为 Unicode 字符，需要为字符编码。 - 如果值为二进制数据，则需要使用 BASE64 编码。 |
| **domain**     | 指定 cookie 所属域名，默认是当前域名                         |
| **path**       | **指定 cookie 在哪个路径（路由）下生效，默认是 '/'**。 如果设置为 `/abc`，则只有 `/abc` 下的路由可以访问到该 cookie，如：`/abc/read`。 |
| **maxAge**     | cookie 失效的时间，单位秒。如果为整数，则该 cookie 在 maxAge 秒后失效。如果为负数，该 cookie 为临时 cookie ，关闭浏览器即失效，浏览器也不会以任何形式保存该 cookie 。如果为 0，表示删除该 cookie 。默认为 -1。 - **比 expires 好用**。 |
| **expires**    | 过期时间，在设置的某个时间点后该 cookie 就会失效。 一般浏览器的 cookie 都是默认储存的，当关闭浏览器结束这个会话的时候，这个 cookie 也就会被删除 |
| **secure**     | 该 cookie 是否仅被使用安全协议传输。安全协议有 HTTPS，SSL等，在网络上传输数据之前先将数据加密。默认为false。 当 secure 值为 true 时，cookie 在 HTTP 中是无效，在 HTTPS 中才有效。 |
| **httpOnly**   | **如果给某个 cookie 设置了 httpOnly 属性，则无法通过 JS 脚本 读取到该 cookie 的信息，但还是能通过 Application 中手动修改 cookie，所以只是在一定程度上可以防止 XSS 攻击，不是绝对的安全** |

> `SQL`注入拼接的是操作数据库的`SQL`语句。`XSS`拼接的是网页的`HTML`代码，一般而言我们是可以拼接出合适的`HTML`代码去执行恶意的`JS`语句（总结：`XSS`就是拼接恶意的`HTML`）

### Session

session 保存在 server端，并分配一个SessionId用户验证用户身份信息。我们把这种能识别哪个请求由哪个用户发起的机制称为 Session（会话机制）它的工作机制如下

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/OyweysCSeLWubRiaj9icTuMphaGqbbQMugHRn2G9xyggKhcicwUAZ7whCU7f4pQeyoJwdZbUYP5ibSFVVriaCAV4mfA/640?wx_fmt=jpeg&wxfrom=5&wx_lazy=1&wx_co=1)

1. 首先用户登录，server 会为用户生成一个 session，为其分配唯一的 sessionId，这个 sessionId 是与某个用户绑定的，也就是说根据此 sessionid（假设为 abc） 可以查询到它到底是哪个用户，然后将此 **sessionid 通过 cookie 传给浏览器**
2. 之后浏览器的每次添加购物车请求中只要在 cookie 里带上 sessionId=abc 这一个键值对即可，server 根据 sessionId 找到它对应的用户后，把传过来的商品 id 保存到 server 中对应用户的购物车即可

可以看到通过这种方式再也不需要在 cookie 里传所有的购物车的商品 id 了，大大减轻了请求的负担！

 **cookie 是存储在 client 的，而 session 保存在 server**，**sessionId 需要借助 cookie 的传递才有意义。**



### session 的痛点（分布式场景下不同机器生成的session不共享）

看起来通过  cookie + session 的方式是解决了问题， 但是我们忽略了一个问题，上述情况能正常工作是因为我们假设 server 是单机工作的，但实际在生产上，为了保障高可用，一般服务器至少需要两台机器，通过负载均衡的方式来决定到底请求该打到哪台机器上。

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/OyweysCSeLWubRiaj9icTuMphaGqbbQMugLdH5ibIV6Thibvic5Qm0zaDyW8eIp3voibfHvc1icwMfX7GicUZnYDibWnWBQ/640?wx_fmt=jpeg&wxfrom=5&wx_lazy=1&wx_co=1)balance

**如图示：客户端请求后，由负载均衡器（如 Nginx）来决定到底打到哪台机器**

假设登录请求打到了 A 机器，A 机器生成了 session 并在 cookie 里添加 sessionId 返回给了浏览器，那么问题来了：下次添加购物车时如果请求打到了 B 或者 C，由于 session 是在 A 机器生成的，此时的 B,C 是找不到 session 的，那么就会发生无法添加购物车的错误，就得重新登录了，此时请问该怎么办。

#### 解决方案：

主要有以下三种方式

> 1、session 复制

A 生成 session 后复制到 B, C，这样每台机器都有一份 session，无论添加购物车的请求打到哪台机器，由于 session 都能找到，故不会有问题

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/OyweysCSeLWubRiaj9icTuMphaGqbbQMugHeLZGsEod55pXopkFU3ewWKxtrJ3gONNaM2ibenQlWdkxXHKXyU0XDA/640?wx_fmt=jpeg&wxfrom=5&wx_lazy=1&wx_co=1)balance (1)

这种方式虽然可行，但缺点也很明显：

1. 同一样的一份 session 保存了多份，数据冗余
2. 如果节点少还好，但如果节点多的话，特别是像阿里，微信这种由于 DAU 上亿，可能需要部署成千上万台机器，这样节点增多复制造成的性能消耗也会很大。

> 2、session 粘连

这种方式是让每个客户端请求只打到固定的一台机器上，比如浏览器登录请求打到 A 机器后，后续所有的添加购物车请求也都打到 A 机器上，Nginx 的 sticky 模块可以支持这种方式，支持按 ip 或 cookie 粘连等等，如按 ip 粘连方式如下

```
upstream tomcats {
　　ip_hash;
　　server 10.1.1.107:88;
　　server 10.1.1.132:80;
}
```

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/OyweysCSeLWubRiaj9icTuMphaGqbbQMugV4JCovgSvfhc86NG0xQdicsoUD4UDU1PFWGOLN1qLqJSuX0iaJhmPvjg/640?wx_fmt=jpeg&wxfrom=5&wx_lazy=1&wx_co=1)

这样的话每个 client 请求到达 Nginx 后，只要它的 ip 不变，根据 ip hash 算出来的值会打到固定的机器上，也就不存在 session 找不到的问题了，当然不难看出这种方式缺点也是很明显，对应的机器挂了怎么办？

> 3、session 共享

这种方式也是目前各大公司普遍采用的方案，将 session 保存在 redis缓存中间件中，请求到来时，各个机器去这些中间件取一下 session 即可。

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/OyweysCSeLWubRiaj9icTuMphaGqbbQMugYynZic3IlPRYEwerUd6lria6kGo8d4SV5efU7ia05gEkZsDVsJ2cEbbNA/640?wx_fmt=jpeg&wxfrom=5&wx_lazy=1&wx_co=1)

缺点其实也不难发现，就是每个请求都要去 redis 取一下 session，多了一次内部连接，消耗了一点性能，另外为了保证 redis 的高可用，必须做集群，当然了对于大公司来说, redis 集群基本都会部署，所以这方案可以说是大公司的首选了。

### Token：no session!

首先请求方输入自己的用户名，密码，然后 server 据此生成 token，客户端拿到 token 后会保存到本地，之后向 server 请求时在请求头带上此 token 即可。

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/OyweysCSeLWubRiaj9icTuMphaGqbbQMugdxicQQmpjVu3JtpPAPc9ldWFCibAqn8k8iaDn0wXMBvWXl6b88f3pPVNQ/640?wx_fmt=jpeg&wxfrom=5&wx_lazy=1&wx_co=1)

相信大家看了上图会发现存在两个问题

1、 token 只存储在浏览器中，服务端却没有存储，这样的话我随便搞个 token 传给 server 也行？

```
答：server 会有一套校验机制，校验这个 token 是否合法。
```

2、怎么不像 session 那样根据 sessionId 找到 userid 呢，这样的话怎么知道是哪个用户？

```
答：token 本身携带 uid 信息
```

第一个问题，如何校验 token 呢？我们可以借鉴 HTTPS 的签名机制来校验。先来看 jwt token 的组成部分

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/OyweysCSeLWubRiaj9icTuMphaGqbbQMugPWYEwl5c4y21ibILKz9cTBSY2ibW91KrjbPW057GMmut8E3ich1Btiad8A/640?wx_fmt=jpeg&wxfrom=5&wx_lazy=1&wx_co=1)

可以看到 token 主要由三部分组成

1. header：指定了签名算法
2. payload：可以指定用户 id，过期时间等非敏感数据
3. Signature: 签名，server 根据 header 知道它该用哪种签名算法，再用密钥根据此签名算法对 head + payload 生成签名，这样一个 token 就生成了。

当 server 收到浏览器传过来的 token 时，它会首先取出 token 中的 header + payload，根据密钥生成签名，然后再与 token 中的签名比对，如果成功则说明签名是合法的，即 token 是合法的。而且你会发现 payload 中存有我们的 userId，所以拿到 token 后直接在 payload 中就可获取 userid，避免了像 session 那样要从 redis 去取的开销

**画外音：header, payload 实际上是以 base64 的形式存在的，文中为了描述方便，省去了这一步。**

你会发现这种方式确实很妙，只要 server 保证密钥不泄露，那么生成的 token 就是安全的，因为如果伪造 token 的话在签名验证环节是无法通过的，就此即可判定 token 非法。

可以看到通过这种方式有效地避免了 token 必须保存在 server 的弊端，实现了分布式存储，不过需要注意的是，token 一旦由 server 生成，它就是有效的，直到过期，无法让 token 失效，除非在 server 为 token 设立一个黑名单，在校验 token 前先过一遍此黑名单，如果在黑名单里则此  token 失效，但一旦这样做的话，那就意味着黑名单就必须保存在 server，这又回到了 session 的模式，那直接用 session 不香吗。所以一般的做法是当客户端登出要让 token 失效时，直接在本地移除 token 即可，下次登录重新生成 token 就好。

另外需要注意的**是 token 一般是放在 header 的 Authorization 自定义头里**，不是放在 Cookie 里的，这主要是为了解决跨域不能共享 Cookie 的问题 （下文详述）

### Cookie 与 Token 的简单总结

> Cookie 有哪些局限性？

1、 Cookie 跨站是不能共享的，这样的话如果你要实现多应用（多系统）的单点登录（SSO），使用 Cookie 来做需要的话就很困难了

**画外音: 所谓单点登录，是指在多个应用系统中，用户只需要登录一次就可以访问所有相互信任的应用系统。**

但如果用 token 来实现 SSO 会非常简单，如下

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/OyweysCSeLWubRiaj9icTuMphaGqbbQMugeC4RTg2easMQgNBmeyOUaXlnAEZr662lNbyuLTUAXFNRNlkqNHUsQA/640?wx_fmt=jpeg&wxfrom=5&wx_lazy=1&wx_co=1)

只要在 header 中的 authorize 字段（或其他自定义）加上 token 即可完成所有跨域站点的认证。

2、 在移动端原生请求是没有 cookie 之说的，而 sessionid 依赖于 cookie，sessionid 就不能用 cookie 来传了，如果用 token 的话，由于它是随着 header 的 authoriize 传过来的，也就不存在此问题，换句话说token 天生支持移动平台，可扩展性好

**综上所述，token 具有存储实现简单，扩展性好这些特点。**

> token 有哪些缺点

那有人就问了，既然 token 这么好，那为什么各个大公司几乎都采用共享 session 的方式呢，可能很多人是第一次听到 token，token 不香吗? token 有以下两点劣势：

```
1、 token 太长了
```

token 是 header, payload 编码后的样式，所以一般要比 sessionId 长很多，很有可能超出 cookie 的大小限制（cookie 一般有大小限制的，如 4kb），如果你在 token 中存储的信息越长，那么 token 本身也会越长，这样的话由于你每次请求都会带上 token，对请求来是个不小的负担

```
2、 不太安全
```

网上很多文章说 token 更安全，其实不然，细心的你可能发现了，我们说 token 是存在浏览器的，再细问，存在浏览器的哪里？既然它太长放在 cookie 里可能导致 cookie 超限，那就只好放在 local storage 里，这样会造成安全隐患，因为 local storage 这类的本地存储是可以被 JS 直接读取的，另外由上文也提到，token 一旦生成无法让其失效，必须等到其过期才行，这样的话如果服务端检测到了一个安全威胁，也无法使相关的 token 失效。

**所以 token 更适合一次性的命令认证，设置一个比较短的有效期**



### 误解: Cookie 相比 token 更不安全，比如 CSRF 攻击

首先我们需要解释下 CSRF 攻击是怎么回事

攻击者通过一些技术手段欺骗用户的浏览器去访问一个自己曾经认证过的网站并运行一些操作（如发邮件，发消息，甚至财产操作如转账和购买商品）。由于浏览器曾经认证过（cookie 里带来 sessionId 等身份认证的信息），所以被访问的网站会认为是真正的用户操作而去运行。

比如用户登录了某银行网站（假设为 **http://www.examplebank.com/**，并且转账地址为 **http://www.examplebank.com/withdraw?amount=1000&transferTo=PayeeName**），登录后 cookie 里会包含登录用户的 sessionid，攻击者可以在另一个网站上放置如下代码

```
<img src="http://www.examplebank.com/withdraw?account=Alice&amount=1000&for=Badman">
```

那么如果正常的用户误点了上面这张图片，由于相同域名的请求会自动带上 cookie，而 cookie 里带有正常登录用户的 sessionid，类似上面这样的转账操作在 server 就会成功，会造成极大的安全风险

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/OyweysCSeLWubRiaj9icTuMphaGqbbQMugB7DH9UZxqKvqfxViaTING0L1nvLCaHQglzjoqoLXI27CqVs7BZqULaA/640?wx_fmt=jpeg&wxfrom=5&wx_lazy=1&wx_co=1)

CSRF 攻击的根本原因在于对于同样域名的每个请求来说，它的 cookie 都会被自动带上，这个是浏览器的机制决定的，所以很多人据此认定 cookie 不安全。

使用 token 确实避免了CSRF 的问题，但正如上文所述，由于 token 保存在 local storage，它会被 JS 读取，**从存储角度来看**也不安全（实际上防护 CSRF 攻击的正确方式是用 CSRF token）

所以不管是 cookie 还是 token，从存储角度来看其实都不安全，都有暴露的风险，我们所说的安全更多的是强调传输中的安全，可以用 HTTPS 协议来传输， 这样的话请求头都能被加密，也就保证了传输中的安全。

其实我们把 cookie 和 token 比较本身就不合理，一个是存储方式，一个是验证方式，正确的比较应该是 session vs token。

### 总结

session 和 token 本质上是没有区别的，都是对用户身份的认证机制，只是他们实现的校验机制不一样而已（一个保存在 server，通过在 redis 等中间件获取来校验，一个保存在 client，通过签名校验的方式来校验），多数场景上使用 session 会更合理，但如果在单点登录，一次性命令认证上使用 token 会更合适，最好在不同的业务场景中合理选型，才能达到事半功倍的效果。







# HTTPS

## Http如何保证安全传输

HTTP 由于是明文传输，所以安全上存在以下三个风险：

1. 窃听风险，通信链路上的数据容易被窃取
2. 篡改风险，没有校验机制，容易被植入广告
3. 冒充身份，因为没有身份验证。

所以如何保证Http的安全传输，就是要解决这三个安全风险。

- **信息加密**：交互信息无法被窃取
- **校验机制**：无法篡改通信内容，篡改了就不能正常显示
- **身份证书**：证明淘宝是真的淘宝网

## Https为什么安全？https如何保证可靠性？HTTPS怎么保证数据安全（三大机制）

- 信息加密机制：**混合加密**的方式实现信息的**机密性**，解决了窃听的风险。

- 信息校验机制：**摘要算法**的方式来实现**完整性**，它能够为数据生成独一无二的「指纹」，指纹用于校验数据的完整性，解决了篡改的风险。

  > 客户端在发送明文之前会通过摘要算法算出明文的「指纹」，发送的时候把「指纹 + 明文」一同加密成密文后，发送给服务器，服务器解密后，用相同的摘要算法算出发送过来的明文，通过比较客户端携带的「指纹」和当前算出的「指纹」做比较，若「指纹」相同，说明数据是完整的。

- 身份校验机制：将服务器公钥放入到**数字证书**中，解决了身份冒充的风险。

  > 客户端先向服务器端索要公钥，然后用公钥加密信息，服务器收到密文后，用自己的私钥解密。
  >
  > 这就存在些问题，如何保证公钥不被篡改和信任度？
  >
  > 所以这里就需要借助第三方权威机构 `CA` （数字证书认证机构），将**服务器公钥放在数字证书**（由数字证书认证机构颁发）中，只要证书是可信的，公钥就是可信的。

## 混合加密算法，为什么https要采用混合加密算法

HTTPS 采用的是**对称加密**和**非对称加密**结合的「混合加密」方式：

- 在通信建立前采用**非对称加密**的方式交换「会话秘钥」，后续就不再使用非对称加密。
- 在通信过程中全部使用**对称加密**的「会话秘钥」的方式加密明文数据。

> `对称加密(Symmetrical Encryption)`顾名思义就是指**加密和解密时使用的密钥都是同样的密钥**。只要保证了密钥的安全性，那么整个通信过程也就是具有了机密性。
>
> AES 的全称是`Advanced Encryption Standard(高级加密标准)`，安全强度很高，性能也很好，是应用最广泛的对称加密算法。
>
> ---
>
> `非对称加密(Asymmetrical Encryption)` 也被称为`公钥加密`，相对于对称加密来说，非对称加密是一种新的改良加密方式。密钥通过网络传输交换，它能够确保及时密钥被拦截，也不会暴露数据信息。非对称加密中有两个密钥，一个是公钥，一个是私钥，公钥进行加密，私钥进行解密。公开密钥可供任何人使用，私钥只有你自己能够知道。
>
> 其中 `RSA` 加密算法是最重要的、最出名的一个了。例如 `DHE_RSA_CAMELLIA128_GCM_SHA256`。它的安全性基于 `整数分解`，使用两个超大素数的乘积作为生成密钥的材料，想要从公钥推算出私钥是非常困难的。
>
> `ECC（Elliptic Curve Cryptography）`也是非对称加密算法的一种，它基于`椭圆曲线离散对数`的数学难题，使用特定的曲线方程和基点生成公钥和私钥， ECDHE 用于密钥交换，ECDSA 用于数字签名。

采用「混合加密」的方式的原因：

- **对称加密**只使用一个密钥，运算速度快，密钥必须保密，无法做到安全的密钥交换。
- **非对称加密**使用两个密钥：公钥和私钥，公钥可以任意分发而私钥保密，解决了密钥交换问题但速度慢。

## Http、Https、两者区别

1. HTTP 是超文本传输协议，信息是明文传输，存在安全风险的问题。HTTPS 则解决 HTTP 不安全的缺陷，在 TCP 和 HTTP 应用层之间加入了 SSL/TLS 安全协议，使得报文能够加密传输。
2. HTTP 连接建立相对简单， TCP 三次握手之后便可进行 HTTP 的报文传输。而 HTTPS 在 TCP 三次握手之后，还需进行 SSL/TLS 的握手过程，才可进入加密报文传输。
3. HTTP 的端口号是 80，HTTPS 的端口号是 443。
4. HTTPS 协议需要向 CA（证书权威机构）申请数字证书，来保证服务器的身份是可信的。



## Http、Https 性能比较

HTTPs肯定比HTTP耗时，这就叫SSL延迟。

```bash
 
$ curl -w "TCP handshake: %{time_connect}, SSL handshake: %{time_appconnect}\n" -so /dev/null https://www.alipay.com
 
TCP handshake: 0.022, SSL handshake: 0.064

```

SSL握手的耗时（64毫秒）大概是TCP握手（22毫秒）的三倍。也就是说，在建立连接的阶段，HTTPs链接比HTTP链接要长3倍的时间，具体数字取决于CPU的快慢和网络状况。

## 介绍Https中间安全层

HTTPS的中间安全层，是HTTPS 为了解决 HTTP 不安全的缺陷，在 TCP传输层和 HTTP 应用层之间加入了 SSL/TLS 安全协议，使得报文能够加密传输。

## ssl协议属于哪一层

属于传输层和网络层之间。





## Https的加密流程、https建立连接的过程、SSL如何加密、Https的TLS的工作原理

> Https加密算法用在哪个步骤？
> 

> SSL/TLS 协议基本流程：
>
> - 客户端向服务器索要并验证服务器的公钥。
> - 双方协商生产「会话秘钥」。
> - 双方采用「会话秘钥」进行加密通信。
>
> 前两步也就是 SSL/TLS 的建立过程，也就是握手阶段。
>
> 所以简单来说就是两个环节：
>
> - 第一个环节， TLS 协议握手过程；RSA算法
> - 第二个环节，握手后的对称加密报文传输。AES算法
>
> SSL/TLS 的「握手阶段」涉及**四次**通信，可见下图：
>
> ![HTTPS 连接建立过程](https://cdn.jsdelivr.net/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/HTTP/23-HTTPS%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B.png)
>
> SSL/TLS 协议建立的详细流程：
>
> *1. ClientHello*
>
> 首先，由客户端向服务器发起加密通信请求，也就是 `ClientHello` 请求。
>
> 在这一步，客户端主要向服务器发送以下信息：
>
> （1）客户端支持的 SSL/TLS 协议版本，如 TLS 1.2 版本。
>
> （2）客户端生产的随机数（`Client Random`），后面用于生产「会话秘钥」。
>
> （3）客户端支持的密码套件列表，如 RSA 加密算法。
>
> *2. SeverHello*
>
> 服务器收到客户端请求后，向客户端发出响应，也就是 `SeverHello`。服务器回应的内容有如下内容：
>
> （1）确认 SSL/ TLS 协议版本，如果浏览器不支持，则关闭加密通信。
>
> （2）服务器生产的随机数（`Server Random`），后面用于生产「会话秘钥」。
>
> （3）确认的密码套件列表，如 RSA 加密算法。
>
> （4）服务器的数字证书。
>
> *3.客户端回应*
>
> 客户端收到服务器的回应之后，首先通过浏览器或者操作系统中的 CA 公钥，确认服务器的数字证书的真实性。
>
> 如果证书没有问题，客户端会从数字证书中取出服务器的公钥，然后使用它加密报文，向服务器发送如下信息：
>
> （1）一个随机数（`pre-master key`）。该随机数会被服务器公钥加密。
>
> （2）加密通信算法改变通知，表示随后的信息都将用「会话秘钥」加密通信。
>
> （3）客户端握手结束通知，表示客户端的握手阶段已经结束。这一项同时把之前所有内容的发生的数据做个摘要，用来供服务端校验。
>
> 上面第一项的随机数是整个握手阶段的第三个随机数，这样服务器和客户端就同时有三个随机数，接着就用双方协商的加密算法，**各自生成**本次通信的「会话秘钥」。
>
> *4. 服务器的最后回应*
>
> 服务器收到客户端的第三个随机数（`pre-master key`）之后，通过协商的加密算法，计算出本次通信的「会话秘钥」。然后，向客户端发送最后的信息：
>
> （1）加密通信算法改变通知，表示随后的信息都将用「会话秘钥」加密通信。
>
> （2）服务器握手结束通知，表示服务器的握手阶段已经结束。这一项同时把之前所有内容的发生的数据做个摘要，用来供客户端校验。
>
> 至此，整个 SSL/TLS 的握手阶段全部结束。接下来，客户端与服务器进入加密通信，就完全是使用普通的 HTTP 协议，只不过用「会话秘钥」加密内容。



## Https建立连接时服务器返回的证书的内容？简述CA证书、如何验证CA证书的可靠性？

一个数字证书通常包含了：

- 公钥；
- 持有者信息；
- 证书认证机构（CA）的信息；
- CA 对这份文件的数字签名及使用的算法；
- 证书有效期；
- 还有一些其他额外信息；

那数字证书的作用，是用来认证公钥持有者的身份，以防止第三方进行冒充。说简单些，证书就是用来告诉客户端，该服务端是否是合法的，因为只有证书合法，才代表服务端身份是可信的。

> ### **我们用证书来认证公钥持有者的身份（服务端的身份），那证书又是怎么来的？又该怎么认证证书呢？**
>
> ####  数字证书签发和验证流程
>
> 如下图图所示，为数字证书签发和验证流程：
>
> ![img](https://cdn.jsdelivr.net/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/https/%E8%AF%81%E4%B9%A6%E7%9A%84%E6%A0%A1%E9%AA%8C.png)
>
> CA 签发证书的过程，如上图左边部分：
>
> - 首先 CA 会把持有者的公钥、用途、颁发者、有效时间等信息打成一个包，然后对这些信息进行 Hash 计算，得到一个 Hash 值；
> - 然后 CA 会使用自己的私钥将该 Hash 值加密，生成 Certificate Signature，也就是 CA 对证书做了签名；
> - 最后将 Certificate Signature 添加在文件证书上，形成数字证书；
>
> 客户端校验服务端的数字证书的过程，如上图右边部分：
>
> - 首先客户端会使用同样的 Hash 算法获取该证书的 Hash 值 H1；
> - 通常浏览器和操作系统中集成了 CA 的公钥信息，浏览器收到证书后可以使用 CA 的公钥解密 Certificate Signature 内容，得到一个 Hash 值 H2 ；
> - 最后比较 H1 和 H2，如果值相同，则为可信赖的证书，否则则认为证书不可信。
>
> #### [#](https://xiaolincoding.com/network/2_http/https_rsa.html#证书链)证书链
>
> 但事实上，证书的验证过程中还存在一个证书信任链的问题，因为我们向 CA 申请的证书一般不是根证书签发的，而是由中间证书签发的，比如百度的证书，从下图你可以看到，证书的层级有三级：
>
> ![img](https://cdn.jsdelivr.net/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/https/baidu%E8%AF%81%E4%B9%A6.png)
>
> 对于这种三级层级关系的证书的验证过程如下：
>
> - 客户端收到 baidu.com 的证书后，发现这个证书的签发者不是根证书，就无法根据本地已有的根证书中的公钥去验证 baidu.com 证书是否可信。于是，客户端根据 baidu.com 证书中的签发者，找到该证书的颁发机构是 “GlobalSign Organization Validation CA - SHA256 - G2”，然后向 CA 请求该中间证书。
> - 请求到证书后发现 “GlobalSign Organization Validation CA - SHA256 - G2” 证书是由 “GlobalSign Root CA” 签发的，由于 “GlobalSign Root CA” 没有再上级签发机构，说明它是根证书，也就是自签证书。应用软件会检查此证书有否已预载于根证书清单上，如果有，则可以利用根证书中的公钥去验证 “GlobalSign Organization Validation CA - SHA256 - G2” 证书，如果发现验证通过，就认为该中间证书是可信的。
> - “GlobalSign Organization Validation CA - SHA256 - G2” 证书被信任后，可以使用 “GlobalSign Organization Validation CA - SHA256 - G2” 证书中的公钥去验证 baidu.com 证书的可信性，如果验证通过，就可以信任 baidu.com 证书。
>
> 在这四个步骤中，最开始客户端只信任根证书 GlobalSign Root CA 证书的，然后 “GlobalSign Root CA” 证书信任 “GlobalSign Organization Validation CA - SHA256 - G2” 证书，而 “GlobalSign Organization Validation CA - SHA256 - G2” 证书又信任 baidu.com 证书，于是客户端也信任 baidu.com 证书。
>
> 总括来说，由于用户信任 GlobalSign，所以由 GlobalSign 所担保的 baidu.com 可以被信任，另外由于用户信任操作系统或浏览器的软件商，所以由软件商预载了根证书的 GlobalSign 都可被信任。
>
> ![img](https://cdn.jsdelivr.net/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/https/%E7%94%A8%E6%88%B7%E4%BF%A1%E4%BB%BB.png)
>
> 操作系统里一般都会内置一些根证书，比如我的 MAC 电脑里内置的根证书有这么多：
>
> ![img](https://cdn.jsdelivr.net/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/https/%E7%B3%BB%E7%BB%9F%E6%A0%B9%E8%AF%81%E4%B9%A6.png)
>
> 这样的一层层地验证就构成了一条信任链路，整个证书信任链验证流程如下图所示：
>
> ![img](https://cdn.jsdelivr.net/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/https/%E8%AF%81%E4%B9%A6%E9%93%BE.png)
>
> 最后一个问题，为什么需要证书链这么麻烦的流程？Root CA 为什么不直接颁发证书，而是要搞那么多中间层级呢？
>
> 这是为了确保根证书的绝对安全性，将根证书隔离地越严格越好，不然根证书如果失守了，那么整个信任链都会有问题




Https如何断定恶意网址
如果晚上0点有大量请求，如何区分恶意与善意请求？

## 如何改善https构建请求速度慢的情况

### 密钥交换算法优化

TLS 1.2 版本如果使用的是 RSA 密钥交换算法，那么需要 4 次握手，也就是要花费 2 RTT，才可以进行应用数据的传输，而且 RSA 密钥交换算法不具备前向安全性。

总之使用 **RSA 密钥交换算法的 TLS 握手过程，不仅慢，而且安全性也不高**。

因此如果可以，尽量**选用 ECDHE 密钥交换**算法替换 RSA 算法，因为该算法由于支持「False Start」，它是“抢跑”的意思，客户端可以在 TLS 协议的第 3 次握手后，第 4 次握手前，发送加密的应用数据，以此将 **TLS 握手的消息往返由 2 RTT 减少到 1 RTT，而且安全性也高，具备前向安全性**。

ECDHE 算法是基于椭圆曲线实现的，不同的椭圆曲线性能也不同，应该尽量**选择 x25519 曲线**，该曲线是目前最快的椭圆曲线。

###  TLS 升级

当然，如果可以，直接把 TLS 1.2 升级成 TLS 1.3，TLS 1.3 大幅度简化了握手的步骤，**完成 TLS 握手只要 1 RTT**，而且安全性更高。

在 TLS 1.2 的握手中，一般是需要 4 次握手，先要通过 Client Hello （第 1 次握手）和 Server Hello（第 2 次握手） 消息协商出后续使用的加密算法，再互相交换公钥（第 3 和 第 4 次握手），然后计算出最终的会话密钥，下图的左边部分就是 TLS 1.2 的握手过程：

![img](https://cdn.jsdelivr.net/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/https%E4%BC%98%E5%8C%96/tls1.2and1.3.png)

上图的右边部分就是 TLS 1.3 的握手过程，可以发现 **TLS 1.3 把 Hello 和公钥交换这两个消息合并成了一个消息，于是这样就减少到只需 1 RTT 就能完成 TLS 握手**。

怎么合并的呢？具体的做法是，客户端在 Client Hello 消息里带上了支持的椭圆曲线，以及这些椭圆曲线对应的公钥。

服务端收到后，选定一个椭圆曲线等参数，然后返回消息时，带上服务端这边的公钥。经过这 1 个 RTT，双方手上已经有生成会话密钥的材料了，于是客户端计算出会话密钥，就可以进行应用数据的加密传输了。

而且，TLS1.3 对密码套件进行“减肥”了， **对于密钥交换算法，废除了不支持前向安全性的 RSA 和 DH 算法，只支持 ECDHE 算法**。

对于对称加密和签名算法，只支持目前最安全的几个密码套件，比如 openssl 中仅支持下面 5 种密码套件：

- TLS_AES_256_GCM_SHA384
- TLS_CHACHA20_POLY1305_SHA256
- TLS_AES_128_GCM_SHA256
- TLS_AES_128_CCM_8_SHA256
- TLS_AES_128_CCM_SHA256

之所以 TLS1.3 仅支持这么少的密码套件，是因为 TLS1.2 由于支持各种古老且不安全的密码套件，中间人可以利用降级攻击，伪造客户端的 Client Hello 消息，替换客户端支持的密码套件为一些不安全的密码套件，使得服务器被迫使用这个密码套件进行 HTTPS 连接，从而破解密文。





​	

**Tcp与Udp区别**

**Udp使用场景**

**UDP包大于1472字节能够发送成功吗？**

**UDP能携带的数据最大长度是多少**

**使用udp还想保证数据不丢失如何处理**

**UDP为什么快？**

**UDP是否会进行数据校验**

**列举使用TCP协议的应用/场景**

**TCP三次握手过程及状态变化**

**三次握手中出现丢包现象如何处理**

**Tcp三次握手四次挥手及对应的状态**

**第三次挥手，如果客户端挂了， 服务端拿不到客户端响应，如何应对？**

**TCP的连接状态有哪些**

**TCP为什么要四次挥手**

**四次挥手timewait的作用**

**四次挥手出现TimeWait的条件**

**服务端time-wait太多，如何解决？**

**服务器存在大量的close-wait状态如何处理**

**close-wait出现大量堆积的时机**

**四次挥手为什么要等待2MSL？**

**Tcp四次挥手何时断开连接？**

**last ack状态作用**

**Tcp流量控制与拥塞控制**

**Tcp如何保证可靠传输**

**TCP为什么要三次握手**

**TCP的最大传输长度是多大**

**如果第一次握手后，服务端宕机会怎样？**

**A、B间有TCP连接，如果B拔网线，TCP连接会怎样**

**TCP滑动窗口的作用**

**TCP为什么粘包？如何处理**

**TCP中nagle算法及其缺点**

**发送方怎么判断丢包？**

**如何设计可靠的UDP**

**closewait的作用**

**列举拥塞控制的几种算法**

**Tcp与Udp相关协议**

**Socket实现三次握手**

**SYN洪泛攻击与应对方案**

**TCP为什么要进行拆包？**

**TCP建立连接后传输数据的具体过程**

**TCP超时重传时间与次数**

**TCP超时重传时间设置**

**TCP协议报文格式**

**Tcp的选择重传机制**

**列举传输层的协议**

**Tcp的慢启动**

**如何验证传输报文是否完整？**

**什么是连接半打开状态**

**Tcp如何判断连接超时？**

**TCP协议的简要介绍**

**快重传与快恢复的区别**

**TCP中有哪些定时器**

**如何快速回收TCP资源**

**TCP的长连接与短连接区别**

**TCP是长连接还是短链接**

**数据接收方还会有滑动窗口吗**

**滑动窗口的大小是如何确定的？**

**如何搭建TCP高并发服务器**

**TCP的特点**

**TCP的延迟主要在哪**

**TCP是怎么判断丢包的?**

**页面渲染过程中是否会建立TCP连接**

**TCP快重传如何判断丢失**

**TCP三次握手为什么要用随机初始化的序号**

**当服务器与客户端建立连接后，服务器端突然断电，客户端会怎样？**

**TCP报文中的端口号是如何获取的**

**TCP建立连接需要的系统调用**

**TCP如何控制建立连接与断开连接**

**TCP 头部大小是固定的吗？**

**如果现在建立一个tcp连接，是不是对单个文件中所有的外部资源都复用这个连接？**

**Linux 内核如何实现 TCP ？**

**TCP 里的 RTT 和 RTO 怎么测量的？**

**UDP报文格式**

**TCP 有哪几种关闭的情况？**

**已经有流量控制为什么还要拥塞控制？**

**一个MTU最大多少字节，最多可包含多少数据**



**简要介绍OSPF协议**

**路由转发方式**

**描述通过IP地址路由到主机的全过程**

**简述ARP协议流程**

**浏览器上输入地址后的整个请求过程**

**OSI七层、五层模型，每一层的作用**

**为什么OSI标准是七层，而实际使用的是五层？**

**Tcp/ip的四层协议**

**DNS工作原理**

**常见网络攻击类型 怎么防范xsrf**

**CSRF的防御措施**

**Socket与WebSocket的区别与联系**

**websocket是如何保证通信可靠**

**列举应用层协议**

**交换机工作原理**

**ICMP，ARP，IGMP原理**

**ARP和RARP的区别**

**路由器工作原理**

**ping的过程**

**ip地址和mac地址的区别**

**网络层报文和报头**

**简述DDoS的攻击方式与原理**

**Socket的系统调用**

**Socket与Channel的区别**

**ajax发生请求的过程**

**网络模型为什么要分层**

**NAT实现原理**

**子网掩码的作用**

**列举并简述路由协议**

**Mac地址与IP地址的关系**

**IPv4地址与IPv6地址的区别**

**DNS使用TCP协议还是UDP协议**

**DNS劫持是什么意思**

**对比分析简单请求与预检请求**

**Socket通信与Tcp通信的比较**

**说说对WebSocket的了解**

**限流和熔断分别适用于哪些场景**

**讲一下CORS**

**什么请求会触发cors的预检，为什么会有预检，预检增加了请求次数，这有什么好处？**

**cors的返回头、cors预请求，什么时候会出发预请求**

**cors要设置哪些参数**

**ajax如何取消请求**

**cdn的原理**

**数据链路层有哪些协议**

**二层交换机和三层交换机的区别**

**分析说明IP层协议**

**URL中的中文字符为什么需要转码**

**dns除了能查ip还能查到什么**

**网关同时接到10个请求，是并行处理还是串行处理？**

**简述黑客攻击某个主机的方法与过程**



**网络中信息传递的顺序（同网段、不同网段）**

**MySQL建立连接的过程**

**网络数据转发的全流程（交换机/路由器报文传输具体流程）**

**如果你使用无线局域网，访问网址很慢如何排查？**

**BS与CS的区别**

**服务端如何记录客户端登陆状态？**

**客户端与服务端建立连接后是否会保持？何时释放？**

**两个页面如何通信（跨浏览器通信，不是同源政策的跨域通信）**

**简要介绍RIP协议**

**列举网络拓扑结构**

**如何实现软路由**

**A能ping通B，B不能ping用A，如何排查问题**

**电脑多网卡，IP数据包如何选择网卡发送**

**IP协议是否可靠并说明原因**

**私网如何访问到百度？**

**公网和私网如何区分？**

**什么是网段？**

**数据链路层的报头和报文**

**OSI 和 TCP/IP 模型之间的区别**

**路由器在OSI模型的哪层**

**列举熟悉的网络协议**

**整体介绍互联网体系架构**

**交换机和路由器的区别**

**QQ能登录但浏览器不能访问网页，分析原因（开放题）**

**如何实现实验室不能访问bilibil(开放题)**

**如何预防XSS攻击**

**静态资源如何加速**

**静态资源与动态资源的区别**

**为什么要动静分离**